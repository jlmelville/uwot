<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="uwot">
<title>Metric Learning with UMAP • uwot</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Metric Learning with UMAP">
<meta property="og:description" content="uwot">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">uwot</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.16.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/uwot.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../articles/index.html">Articles</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/jlmelville/uwot/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Metric Learning with UMAP</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/jlmelville/uwot/blob/HEAD/vignettes/articles/metric-learning.Rmd" class="external-link"><code>vignettes/articles/metric-learning.Rmd</code></a></small>
      <div class="d-none name"><code>metric-learning.Rmd</code></div>
    </div>

    
    
<p>Among other things, UMAP provides two interesting extensions to its
basic dimensionality reduction. First, it can do a supervised embedding,
where labels (or numeric values) are leveraged so that similar points
are closer together than they would otherwise be. Second, it can do
metric learning, by embedding out-of-sample points based on an existing
embedding.</p>
<p>This document shows how to do it in <code>uwot</code>, but more
information is available in UMAP’s <a href="https://umap-learn.readthedocs.io/en/latest/supervised.html" class="external-link">documentation</a>.</p>
<p>The example dataset used is <a href="https://github.com/zalandoresearch/fashion-mnist" class="external-link">Fashion
MNIST</a>. One way to download it in uwot-ready form is:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">devtools</span><span class="fu">::</span><span class="fu">install_github</span><span class="op">(</span><span class="st">"jlmelville/snedata"</span><span class="op">)</span></span>
<span><span class="va">fashion</span> <span class="op">&lt;-</span> <span class="fu">snedata</span><span class="fu">::</span><span class="fu">download_fashion_mnist</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>The Fashion MNIST dataset contains 70,000 images of fashion items, in
one of ten classes. A factor column, <code>Label</code> contains the id
of each item (from <code>0</code> to <code>9</code>) for backwards
compatibility with the MNIST dataset, which Fashion MNIST is designed to
be a drop-in replacement for. A more descriptive, but entirely
equivalent, factor column, <code>Description</code> provides a short
text string to describe the classes, e.g. the <code>Description</code>
<code>"Coat"</code> and the <code>Label</code> <code>4</code> are
equivalent.</p>
<div class="section level3">
<h3 id="visualization">Visualization<a class="anchor" aria-label="anchor" href="#visualization"></a>
</h3>
<p>To produce the plots below, I used my <a href="https://github.com/jlmelville/vizier" class="external-link">vizier package</a>, which
can be installed using:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">devtools</span><span class="fu">::</span><span class="fu">install_github</span><span class="op">(</span><span class="st">"jlmelville/vizier"</span><span class="op">)</span></span></code></pre></div>
<p>I’ll show the commands to produce the plots before they are
displayed.</p>
</div>
<div class="section level2">
<h2 id="supervised-learning">Supervised Learning<a class="anchor" aria-label="anchor" href="#supervised-learning"></a>
</h2>
<p>We’ll compare the supervised result with a standard run of UMAP:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span>
<span><span class="va">fashion_umap</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap.html">umap</a></span><span class="op">(</span><span class="va">fashion</span><span class="op">)</span></span></code></pre></div>
<p>For supervised learning, provide a suitable vector of labels as the
<code>y</code> argument to <code>umap</code> (or
<code>tumap</code>):</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span>
<span><span class="va">fashion_sumap</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap.html">umap</a></span><span class="op">(</span><span class="va">fashion</span>, y <span class="op">=</span> <span class="va">fashion</span><span class="op">$</span><span class="va">Description</span><span class="op">)</span></span></code></pre></div>
<p>Let’s take a look at the results, the unsupervised embedding on the
left, and the supervised version on the right:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">vizier</span><span class="fu">::</span><span class="fu">embed_plot</span><span class="op">(</span><span class="va">fashion_umap</span>, <span class="va">fashion</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, title <span class="op">=</span> <span class="st">"Fashion UMAP"</span>, alpha_scale <span class="op">=</span> <span class="fl">0.075</span><span class="op">)</span></span>
<span><span class="fu">vizier</span><span class="fu">::</span><span class="fu">embed_plot</span><span class="op">(</span><span class="va">fashion_sumap</span>, <span class="va">fashion</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, title <span class="op">=</span> <span class="st">"Fashion Supervised UMAP"</span>, alpha_scale <span class="op">=</span> <span class="fl">0.075</span><span class="op">)</span></span></code></pre></div>
<table class="table">
<colgroup>
<col width="51%">
<col width="48%">
</colgroup>
<tbody><tr class="odd">
<td align="center"><img src="img/metric-learning/umap_fashion_all.png" alt="Fashion UMAP"></td>
<td align="center"><img src="img/metric-learning/sumap_fashion_all.png" alt="Fashion Supervised UMAP"></td>
</tr></tbody>
</table>
<p>Clearly, the supervised UMAP has done a much better job of separating
out the classes, although it has also retained the relative location of
the clusters pretty well, too.</p>
</div>
<div class="section level2">
<h2 id="metric-learning">Metric Learning<a class="anchor" aria-label="anchor" href="#metric-learning"></a>
</h2>
<p>It’s also possible to use an existing embedding to embed new points.
Fashion MNIST comes with its own suggested split into training (the
first 60,000 images) and test (the remaining 10,000 images) sets, so
we’ll use that:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fashion_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">fashion</span>, <span class="fl">60000</span><span class="op">)</span></span>
<span><span class="va">fashion_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">fashion</span>, <span class="fl">10000</span><span class="op">)</span></span></code></pre></div>
<p>Training proceeds by running UMAP normally, but we need to return
more than just the embedded coordinates. To return enough information to
embed new data, we need to set the <code>ret_model</code> flag when we
run <code>umap</code>. This will return a list. The embedded coordinates
can be found as the <code>embedding</code> item.</p>
<div class="section level3">
<h3 id="training">Training<a class="anchor" aria-label="anchor" href="#training"></a>
</h3>
<p>For training, we shall continue to use both standard UMAP:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span>
<span><span class="va">fashion_umap_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap.html">umap</a></span><span class="op">(</span><span class="va">fashion_train</span>, ret_model <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>and supervised UMAP:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span>
<span><span class="va">fashion_sumap_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap.html">umap</a></span><span class="op">(</span><span class="va">fashion_train</span>, ret_model <span class="op">=</span> <span class="cn">TRUE</span>, y <span class="op">=</span> <span class="va">fashion_train</span><span class="op">$</span><span class="va">Description</span><span class="op">)</span></span></code></pre></div>
<p>These results shouldn’t be that different from the full-dataset
embeddings, but let’s take a look anyway:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">vizier</span><span class="fu">::</span><span class="fu">embed_plot</span><span class="op">(</span><span class="va">fashion_umap_train</span><span class="op">$</span><span class="va">embedding</span>, <span class="va">fashion_train</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, title <span class="op">=</span> <span class="st">"Fashion Train UMAP"</span>, alpha_scale <span class="op">=</span> <span class="fl">0.075</span><span class="op">)</span></span>
<span><span class="fu">vizier</span><span class="fu">::</span><span class="fu">embed_plot</span><span class="op">(</span><span class="va">fashion_sumap_train</span><span class="op">$</span><span class="va">embedding</span>, <span class="va">fashion_train</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, title <span class="op">=</span> <span class="st">"Fashion Train Supervised UMAP"</span>, alpha_scale <span class="op">=</span> <span class="fl">0.075</span><span class="op">)</span></span></code></pre></div>
<table class="table">
<colgroup>
<col width="51%">
<col width="48%">
</colgroup>
<tbody><tr class="odd">
<td align="center"><img src="img/metric-learning/umap_fashion_train.png" alt="Fashion UMAP Train"></td>
<td align="center"><img src="img/metric-learning/sumap_fashion_train.png" alt="Fashion Supervised UMAP Train"></td>
</tr></tbody>
</table>
<p>Everything looks in order here. The standard UMAP training plot is
flipped along the y-axis compared to the full dataset, but that doesn’t
matter.</p>
</div>
<div class="section level3">
<h3 id="embedding-new-data">Embedding New Data<a class="anchor" aria-label="anchor" href="#embedding-new-data"></a>
</h3>
<p>To embed new data, use the <code>umap_transform</code> function. Pass
the new data and the trained UMAP model. There’s no difference between
using a standard UMAP model:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span>
<span><span class="va">fashion_umap_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap_transform.html">umap_transform</a></span><span class="op">(</span><span class="va">fashion_test</span>, <span class="va">fashion_umap_train</span><span class="op">)</span></span></code></pre></div>
<p>or a supervised UMAP model:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1337</span><span class="op">)</span></span>
<span><span class="va">fashion_sumap_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap_transform.html">umap_transform</a></span><span class="op">(</span><span class="va">fashion_test</span>, <span class="va">fashion_sumap_train</span><span class="op">)</span></span></code></pre></div>
<p>Here are the results:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">vizier</span><span class="fu">::</span><span class="fu">embed_plot</span><span class="op">(</span><span class="va">fashion_umap_test</span>, <span class="va">fashion_test</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, title <span class="op">=</span> <span class="st">"Fashion Test UMAP"</span>, alpha_scale <span class="op">=</span> <span class="fl">0.075</span><span class="op">)</span></span>
<span><span class="fu">vizier</span><span class="fu">::</span><span class="fu">embed_plot</span><span class="op">(</span><span class="va">fashion_sumap_test</span>, <span class="va">fashion_test</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, title <span class="op">=</span> <span class="st">"Fashion Test Supervised UMAP"</span>, alpha_scale <span class="op">=</span> <span class="fl">0.075</span><span class="op">)</span></span></code></pre></div>
<table class="table">
<colgroup>
<col width="51%">
<col width="48%">
</colgroup>
<tbody><tr class="odd">
<td align="center"><img src="img/metric-learning/umap_fashion_test.png" alt="Fashion UMAP Test"></td>
<td align="center"><img src="img/metric-learning/sumap_fashion_test.png" alt="Fashion Supervised UMAP Train"></td>
</tr></tbody>
</table>
<p>The test data results are very obviously embedded in a similar way to
the training data. Of particular interest are the test results with the
supervised model, where the clusters stay well separated compared to the
unsupervised results, although there are some misclassifications of
shirts, t-shirts, coats and pullover classes (the green, blue and red
clusters on the right of the supervised UMAP plot).</p>
</div>
<div class="section level3">
<h3 id="accuracy-results">Accuracy Results<a class="anchor" aria-label="anchor" href="#accuracy-results"></a>
</h3>
<p>To quantify this improvement, we can look at accuracy in predicting
the test set labels by using the embedded coordinates as a k-nearest
neighbor classifier. There are a variety of ways I can imagine using the
information in the model, but two obvious ones are to use the label of
the nearest neighbor, (<code>1NN</code>) or take a vote using the
<code>n_neighbors</code> (in this case, 15) nearest neighbors
(<code>15NN</code>).</p>
<p>For standard UMAP, the <code>1NN</code> accuracy is 71%, and the
<code>15NN</code> accuracy is 77%. Using supervised UMAP, these
accuracies improve to 83% and 84%, respectively. So quantitatively, the
supervised UMAP is a big help in correctly classifying the test
data.</p>
<p>To put these numbers in perspective, we can carry out similar
calculations using the input data directly. Here, the <code>1NN</code>
accuracy is 85% and the <code>15NN</code> accuracy is 84%. Possibly, the
lack of improvement on going from 1 to 15 neighbors indicates that a
different value of the <code>n_neighbors</code> parameter could improve
the embedding, but I haven’t pursued that.</p>
<p>At any rate, it’s clear that the Fashion MNIST images do not embed
well in two dimensions, although supervised UMAP gets impressively close
to matching the high dimensional results. Maybe supervised UMAP can do
even better by a suitable choice of <code>target_weight</code> and
<code>n_components</code> on top of fiddling with
<code>n_neighbors</code>.</p>
<p>The Fashion MNIST website contains a page that shows the accuracy
using 129 <a href="http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/" class="external-link">scikit-learn
methods</a>, and the <code>15NN</code> supervised UMAP accuracy puts us
in the top 60, which isn’t bad, considering the only hyperparameter
search I did was to look at <code>1NN</code> and <code>15NN</code>.
However, although the highest accuracy reported on that page is 89.7%,
the <a href="https://github.com/zalandoresearch/fashion-mnist#benchmark" class="external-link">deep
learning results</a> achieve 90-97%.</p>
</div>
</div>
<div class="section level2">
<h2 id="supervised-umap-numerical-y">Supervised UMAP: Numerical Y<a class="anchor" aria-label="anchor" href="#supervised-umap-numerical-y"></a>
</h2>
<p>Here’s an example of using supervised UMAP with a numerical target
vector. We shall use the <code>diamonds</code> dataset that comes with
the <a href="https://cran.r-project.org/package=ggplot2" class="external-link">ggplot2</a>
package, as it is of a similar size to MNIST.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="op">?</span><span class="va">diamonds</span></span></code></pre></div>
<p>There are 10 variables associated with each diamond: five numeric
values related to the geometry of the diamonds (<code>table</code>,
<code>x</code>, <code>y</code>, <code>z</code> and <code>depth</code>),
three factors that measure the quality of the diamond (<code>cut</code>,
<code>color</code> and <code>clarity</code>), and the <code>price</code>
in dollars. The <code>price</code> seems like a perfect candidate for
the sort of thing we’d want as the target vector, leaving the other nine
variables to be used for the dimensionality reduction.</p>
<p><code>uwot</code>’s implementation of UMAP uses all numeric columns
in can find in its calculations, so to avoid including the
<code>price</code> in the non-supervised part of UMAP, let’s create a
new data frame, initially with the geometric data:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dia</span> <span class="op">&lt;-</span> <span class="va">diamonds</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"carat"</span>, <span class="st">"x"</span>, <span class="st">"y"</span>, <span class="st">"z"</span>, <span class="st">"table"</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<p>The <code>depth</code> column is related to <code>x</code>,
<code>y</code> and <code>z</code> (albeit non-linearly) so I’m not going
to include it.</p>
<p>Additionally, the factors <code>cut</code>, <code>color</code> and
<code>clarity</code> are all ordinal variables, i.e. their categories
can be ordered, so we can convert these to a numeric scale and include
them as well:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dia</span><span class="op">$</span><span class="va">cut</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">diamonds</span><span class="op">$</span><span class="va">cut</span><span class="op">)</span></span>
<span><span class="va">dia</span><span class="op">$</span><span class="va">color</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">diamonds</span><span class="op">$</span><span class="va">color</span><span class="op">)</span></span>
<span><span class="va">dia</span><span class="op">$</span><span class="va">clarity</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">diamonds</span><span class="op">$</span><span class="va">clarity</span><span class="op">)</span></span></code></pre></div>
<p>We now have a dataset with 53,940 rows and 8 columns. There are 360
duplicates, but it doesn’t seem to affect the results particularly.</p>
<p>Now, I’m not saying that this is the trickiest dataset to extract any
meaning from. First, let’s look at some standard unsupervised results.
For starters, here’s a plot of the first two principal components, using
the <a href="https://cran.r-project.org/package=irlba" class="external-link">irlba</a>
package:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dia_pca</span> <span class="op">&lt;-</span> <span class="fu">irlba</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/irlba/man/prcomp_irlba.html" class="external-link">prcomp_irlba</a></span><span class="op">(</span><span class="va">dia</span>, n <span class="op">=</span> <span class="fl">2</span>, scale. <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu">vizier</span><span class="fu">::</span><span class="fu">embed_plot</span><span class="op">(</span><span class="va">dia_pca</span><span class="op">$</span><span class="va">x</span>, <span class="va">diamonds</span><span class="op">$</span><span class="va">price</span>, title <span class="op">=</span> <span class="st">"Diamonds PCA"</span>, color_scheme <span class="op">=</span> <span class="st">"RColorBrewer::Spectral"</span>, alpha_scale <span class="op">=</span> <span class="fl">0.1</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, pc_axes <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="img/metric-learning/dia_pca.png" alt="Diamonds PCA"><div class="figcaption">Diamonds PCA</div>
</div>
<p>Because the different columns have different units and meaning, I set
<code>scale. = TRUE</code> to equalize their variances. The color scheme
is “Spectral” palette from ColorBrewer: red indicates a low price and
blue a high price. Despite the majority of the dataset being clumped
together in the plot due to some outliers you can’t really see, the
progression of prices from low to high is already pretty well captured
with two components.</p>
<p>Anyway, let’s see what UMAP does with it. Like with PCA, the columns
are all scaled to have equal variance (<code>scale = TRUE</code>):</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dia_umap</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap.html">umap</a></span><span class="op">(</span><span class="va">dia</span>, scale <span class="op">=</span> <span class="cn">TRUE</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu">vizier</span><span class="fu">::</span><span class="fu">embed_plot</span><span class="op">(</span><span class="va">dia_umap</span>, <span class="va">diamonds</span><span class="op">$</span><span class="va">price</span>, title <span class="op">=</span> <span class="st">"Diamonds UMAP"</span>, color_scheme <span class="op">=</span> <span class="st">"RColorBrewer::Spectral"</span>, alpha_scale <span class="op">=</span> <span class="fl">0.1</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, pc_axes <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="img/metric-learning/dia_umap.png" alt="Diamonds UMAP"><div class="figcaption">Diamonds UMAP</div>
</div>
<p>Not bad. The high price diamonds are clumped together in their own
little clusters in the middle of the plot. On this occasion, I prefer
the layout that’s initialized from the PCA results, though:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dia_umap_from_pca</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap.html">umap</a></span><span class="op">(</span><span class="va">dia</span>, scale <span class="op">=</span> <span class="cn">TRUE</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span>, init <span class="op">=</span> <span class="va">dia_pca</span><span class="op">$</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="fu">vizier</span><span class="fu">::</span><span class="fu">embed_plot</span><span class="op">(</span><span class="va">dia_umap_from_pca</span>, <span class="va">diamonds</span><span class="op">$</span><span class="va">price</span>, title <span class="op">=</span> <span class="st">"Diamonds UMAP (PCA init)"</span>, color_scheme <span class="op">=</span> <span class="st">"RColorBrewer::Spectral"</span>, alpha_scale <span class="op">=</span> <span class="fl">0.1</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, pc_axes <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="img/metric-learning/dia_umap_from_pca.png" alt="Diamonds UMAP from PCA"><div class="figcaption">Diamonds UMAP from PCA</div>
</div>
<p>This maintains the global structure of the PCA result. Rather than
have to separately create the PCA, you can also use
<code>init = "pca"</code> and get the same results (<code>uwot</code>
uses <code>irlba</code> internally for this, so there’s no loss of
speed).</p>
<p>Onto the supervised result. Results are not particularly affected by
the choice of initialization, so for simplicity we’ll just use the
standard spectral initialization:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dia_sumap</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap.html">umap</a></span><span class="op">(</span><span class="va">dia</span>, scale <span class="op">=</span> <span class="cn">TRUE</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span>, y <span class="op">=</span> <span class="va">diamonds</span><span class="op">$</span><span class="va">price</span><span class="op">)</span></span>
<span><span class="fu">vizier</span><span class="fu">::</span><span class="fu">embed_plot</span><span class="op">(</span><span class="va">dia_sumap</span>, <span class="va">diamonds</span><span class="op">$</span><span class="va">price</span>, title <span class="op">=</span> <span class="st">"Diamonds Supervised UMAP"</span>, color_scheme <span class="op">=</span> <span class="st">"RColorBrewer::Spectral"</span>, alpha_scale <span class="op">=</span> <span class="fl">0.1</span>, cex <span class="op">=</span> <span class="fl">0.5</span>, pc_axes <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="img/metric-learning/dia_sumap.png" alt="Diamonds Supervised UMAP"><div class="figcaption">Diamonds Supervised UMAP</div>
</div>
<p>As expected, the embedding is now even more well-organized along the
price of the diamonds.</p>
<p>There is a visible gap between the lowest price diamonds (on the
right) and the rest of the embedding. If you increase the
<code>n_epochs</code> parameter and allow the optimization to proceed,
this gap increases substantially, making the plot harder to read.
Adjusting the <code>n_epochs</code> parameter, along with the
<code>target_n_neighbors</code> and <code>target_weight</code>
parameters may be required to strike the right balance. At the time of
writing, I’m not aware of many examples of supervised UMAP with a
numeric vector (in fact none except this thing I just wrote) so I cannot
provide a lot of sage wisdom on this matter.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by James Melville.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.8.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
