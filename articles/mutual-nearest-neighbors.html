<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>UMAP with Mutual Nearest Neighbors • uwot</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><script src="../extra.js"></script><meta property="og:title" content="UMAP with Mutual Nearest Neighbors">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">uwot</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.3</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/uwot.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/index.html">Articles</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/jlmelville/uwot/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>UMAP with Mutual Nearest Neighbors</h1>
            <h3 data-toc-skip class="subtitle">The Balanced Mutual
Nearest Neighbors Graph</h3>
            
            <h4 data-toc-skip class="date">December 25 2024</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/jlmelville/uwot/blob/master/vignettes/articles/mutual-nearest-neighbors.Rmd" class="external-link"><code>vignettes/articles/mutual-nearest-neighbors.Rmd</code></a></small>
      <div class="d-none name"><code>mutual-nearest-neighbors.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Traditionally, dimensionality reduction methods make use of the
k-nearest neighbors graph but there are some exceptions: <a href="https://github.com/eamid/trimap" class="external-link">Trimap</a> and <a href="https://jmlr.org/papers/v22/20-1061.html" class="external-link">PaCMAP</a> use an
extended version of k-nearest neighbors, based on the “generalized”
distances used in <a href="https://papers.nips.cc/paper/2004/hash/40173ea48d9567f1f393b20c855bb40b-Abstract.html" class="external-link">self-tuning
spectral clustering</a>, and PaCMAP goes further to also sample the kth
closest neighbors from a locally sampled batch. <a href="https://arxiv.org/abs/2412.15426" class="external-link">LocalMAP</a> also adjusts the
neighbor graph dynamically during the embedding by sampling distances of
the embedded points.</p>
<p>For the purposes of producing better-separated clusters, <a href="https://arxiv.org/abs/2108.05525" class="external-link">Dalmia and Sia</a> (see also the
<a href="https://umap-learn.readthedocs.io/en/latest/mutual_nn_umap.html" class="external-link">article
in the UMAP docs</a>) consider the mutual nearest neighbors (augmented
with some extra neighbors).</p>
<p>The way PaCMAP uses its neighbors is beyond the architecture of
<code>uwot</code> to handle easilt, but the mutual nearest neighbors
graph is something that <code>uwot</code> can deal with. As detailed in
the article on <code>uwot</code>’s <a href="https://jlmelville.github.io/uwot/articles/nearest-neighbors-format.html">nearest
neighbors format</a>, we can provide as input a sparse distance matrix
to represent nearest neighbors, giving substantial flexibility. However,
it’s not always easy to take advantage of that. Here I will show some
code that can generate a suitably-massaged mutual nearest neighbors
graph and see if it has any effect on UMAP.</p>
</div>
<div class="section level2">
<h2 id="the-problem-with-symmetrized-k-nearest-neighbors">The Problem With Symmetrized k-Nearest Neighbors<a class="anchor" aria-label="anchor" href="#the-problem-with-symmetrized-k-nearest-neighbors"></a>
</h2>
<p>Although in a kNN graph each item only has k neighbors, any workable
dimensionality reduction working on the kNN graph as input will
symmetrize that graph, otherwise optimization is difficult. The outcome
of symmetrizing the knn graph is that if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
is a neighbor of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
in the kNN graph,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
is also guaranteed to be a neighbor of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
in the symmetrized graph and <em>vice versa</em>. If one item tends to
show up in a lot of the kNN lists of multiple items, the symmetrization
means that there can be up to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
edges involving that very popular item. These are called hubs and not
only do they make search on the graph more difficult (that item will be
likely to show up in most queries) but because for a given
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
there are a limited number of edges to distribute over the dataset, some
items are not getting their fair share. This is more likely to lead to
outliers points that get embedded far away from the main body of the
data as they have no particularly strong bonds to the rest of the
data.</p>
</div>
<div class="section level2">
<h2 id="mutual-k-nearest-neighbors">Mutual k-Nearest Neighbors<a class="anchor" aria-label="anchor" href="#mutual-k-nearest-neighbors"></a>
</h2>
<p>You can think of the mutual k-nearest neighbors graph (the MNN graph)
as being a symmetrized kNN graph where edges only appear if item
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
was a neighbor of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math><em>and</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
was a neighbor of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>:
in the symmetrized kNN graph described above the requirement is only
that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
be a neighbor of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math><em>or</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
be a neighbor of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>.
This means that an item can have no more than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
mutual neighbors. Hub problem solved.</p>
</div>
<div class="section level2">
<h2 id="the-problem-with-mutual-k-nearest-neighbors">The Problem with Mutual k-Nearest Neighbors<a class="anchor" aria-label="anchor" href="#the-problem-with-mutual-k-nearest-neighbors"></a>
</h2>
<p>The downside of the MNN graph is that even in very well-behaved kNN
graphs, the MNN will contain several items with no edges to any other
item: while they have
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
nearest neighbors, none of those neighbors reciprocate. UMAP requires
local connectivity, so it cannot handle a use case where we have such
Billy no-mates items.</p>
<p>As a result, the Dalmia and Sia paper has to go to some extra lengths
to augment the MNN graph with some extra nodes which you can see at <a href="https://github.com/adalmia96/umap-mnn" class="external-link">their repo</a>. This
involves minimum spanning trees and Djikstra’s algorithm to add new
nodes (and distances via the path length).</p>
<p>One alternative they consider is to take any fully disconnected nodes
and re-add the first nearest neighbor. They cite a paper by <a href="https://link.springer.com/chapter/10.1007/978-3-642-40994-3_11" class="external-link">de
Souza, Rezende and Batista</a> for this, but there’s no extra detail in
that paper, the authors just note that they do this to avoid the
disconnected nodes.</p>
<p>It should be said that this “adjacent neighbor” approach to MNN
augmentation does not work very well, leading to a lot of disconnect
components and small clusters of points scattered over the embedding.
This is not very surprising.</p>
</div>
<div class="section level2">
<h2 id="adding-back-extra-neighbors-the-balanced-mutual-nearest-neighbors-graph">Adding Back Extra Neighbors: The Balanced Mutual Nearest Neighbors
Graph<a class="anchor" aria-label="anchor" href="#adding-back-extra-neighbors-the-balanced-mutual-nearest-neighbors-graph"></a>
</h2>
<p>As I don’t currently fancy implementing any of the path neighbor
approach, I propose the following strategy: just add back more than one
neighbor to disconnected nodes. In fact, we would probably do well to
ensure every item in the dataset has at least
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
neighbors where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>&lt;</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">m \lt k</annotation></semantics></math>,
not just items which are completely disconnected, as we can already see
that items with only one neighbor don’t do a good job. Obviously adding
back all the neighbors would recreate the original symmetrized kNN
graph, so we want to keep
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
small, but bigger than one.</p>
<p>To name this concept I am going with the “Balanced MNN graph” where
“balanced” is meant to suggest that we are trying to ensure that no node
is left too isolated in the MNN graph. To be specific with numbers I
will refer to a
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>)-BMNN
graph. I would welcome hearing if there is existing literature with a
different (probably better) name.</p>
</div>
<div class="section level2">
<h2 id="creating-the-bmnn">Creating the BMNN<a class="anchor" aria-label="anchor" href="#creating-the-bmnn"></a>
</h2>
<p>The basic formula for creating the BMNN graph is as follows:</p>
<ol style="list-style-type: decimal">
<li>Create the kNN graph.</li>
<li>Form the equivalent MNN graph.</li>
<li>Are there any nodes with fewer than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
neighbors? If not, we stop. Otherwise:</li>
<li>Add back the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>th-nearest
neighbor from the kNN graph to each of those nodes.</li>
<li>Go to step 3.</li>
</ol>
<p>The loop in steps 3-5 must terminate in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
steps: at worst, for items with 0 neighbors, we add all the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>-th
nearest neighbors. For items with
1-(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>-1)
neighbors, we don’t know if the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>-th
nearest neighbor is already a neighbor. If it isn’t we are one step
closer to termination. If it is, then adding the edge will do nothing.
So we can’t add more than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
edges to any node and none of these nodes will get too many edges
added.</p>
<p>Creating the MNN from the sparse kNN representation is easy, assuming
your distances are symmetrical:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sp_mutual</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">sp</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">sp_t</span> <span class="op">&lt;-</span> <span class="fu">Matrix</span><span class="fu">::</span><span class="fu">t</span><span class="op">(</span><span class="va">sp</span><span class="op">)</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">sp</span> <span class="op">*</span> <span class="va">sp_t</span><span class="op">)</span></span>
<span>  <span class="va">res</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Balancing the MNN is a bit more involved, especially if you want it
to be efficient and not do anything disastrous like accidentally attempt
to turn your sparse matrix dense. We must go from 5 lines of code to
more than 100. Below is the code for your delight and delectation. I may
officially export this from <code>uwot</code> some day, but this remains
an experiment for now for you to copy and paste.</p>
<p>Input to <code>balance_mnn</code> is:</p>
<ul>
<li>
<code>nn_graph</code> – the dense representation of the k-nearest
neighbors, i.e. a list of two dense matrices, <code>idx</code> and
<code>dist</code> both of dimensions <code>(n, k)</code>. See the <a href="https://jlmelville.github.io/uwot/articles/nearest-neighbors-format.html">article
on the nearest neighbor format</a> for more. <code>uwot</code> exports
in this format, and so does <a href="https://cran.r-project.org/package=rnndescent" class="external-link">rnndescent</a>.</li>
<li>
<code>k</code> – optionally specify the size of the <code>l</code>
nearest neighbors to use. If you omit this, all the neighbors in
<code>nn_graph</code> will be used. Because generating nearest neighbors
is time-consuming, you may wish to create a large neighbor graph once
(e.g. set <code>k = 50</code> or <code>k = 150</code>) and then use a
smaller subset as the need arises (e.g. 15 is typical for UMAP). The
<code>nng</code> helper function above can do this. Pro-tip: I use
<code><a href="https://jlmelville.github.io/rnndescent/reference/brute_force_knn.html" class="external-link">rnndescent::brute_force_knn</a></code> to generate exact nearest
neighbors for <code>k = 150</code> and then save them once and for all.
My now rather decrepit 8th gen Intel laptop still has enough juice to
crank through datasets of up to 100,000 items and up to 10,000 features
with 6 threads in a “reasonable” amount of time, where “reasonable” for
me means anything up to a few hours, but not “going on holiday for two
weeks”.</li>
<li>
<code>m</code> – minimum number of neighbors to ensure each item
has. This needs to be at least two.</li>
</ul>
<p>One slightly weird thing about specifying <code>m</code> is that you
will actually get back one less edge than the value you ask for. This is
because in the dense format every item’s nearest neighbor is itself with
a distance of zero. This disappears when we convert to the sparse
format. As a result your dense k-nearest neighbor graph only contains
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k-1</annotation></semantics></math>
different neighbors for each item. The self-neighbor thing counting as
one of the neighbors is always how UMAP has done it, so we won’t be
changing the habit of a lifetime. You will just have to remember to
reproduce the “adjacent neighbor” method you must specify
<code>m = 2</code>. The function won’t let you go lower than
<code>m = 2</code> anyway.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># create an m-balanced k-mutual nearest neighbors graph from the dense k-nearest</span></span>
<span><span class="co"># neighbors graph `nn-graph`. m must be less than or equal to k. If `k` is not</span></span>
<span><span class="co"># specified then all of the neighbors are used.</span></span>
<span><span class="va">balance_mnn</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">nn_graph</span>, <span class="va">m</span>, <span class="va">k</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">m</span> <span class="op">&lt;</span> <span class="fl">2</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/stop.html" class="external-link">stop</a></span><span class="op">(</span><span class="st">"m must be at least 2"</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">k</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">nn_graph</span> <span class="op">&lt;-</span> <span class="fu">nng</span><span class="op">(</span><span class="va">nn_graph</span>, <span class="va">k</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="va">k</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">nn_graph</span><span class="op">$</span><span class="va">idx</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">m</span> <span class="op">&gt;</span> <span class="va">k</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/stop.html" class="external-link">stop</a></span><span class="op">(</span><span class="st">"m must be less than or equal to k"</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="co"># create the mutual neighbors as a sparse matrix</span></span>
<span>  <span class="co"># each item's neighbors distances are stored by column</span></span>
<span>  <span class="va">bmnn</span> <span class="op">&lt;-</span> <span class="fu">k_to_m</span><span class="op">(</span><span class="va">nn_graph</span><span class="op">)</span></span>
<span>  <span class="va">bmnn_adj</span> <span class="op">&lt;-</span> <span class="fu">sp_to_adj</span><span class="op">(</span><span class="va">bmnn</span><span class="op">)</span></span>
<span>  <span class="va">bmnn_edges</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">colSums</a></span><span class="op">(</span><span class="va">bmnn_adj</span><span class="op">)</span></span>
<span>  <span class="va">too_few_edges_mask</span> <span class="op">&lt;-</span> <span class="va">bmnn_edges</span> <span class="op">&lt;</span> <span class="op">(</span><span class="va">m</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span>  <span class="co"># add edges back from the knn graph to "fill up" any items with too few edges</span></span>
<span>  <span class="co"># do it one column at a time to avoid over-filling any one item</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">l</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">2</span>, to <span class="op">=</span> <span class="va">m</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">too_few_edges_mask</span><span class="op">)</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="kw">break</span></span>
<span>    <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/r/base/message.html" class="external-link">message</a></span><span class="op">(</span><span class="st">"Iter "</span>, <span class="va">l</span>, <span class="st">" cols to process: "</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">too_few_edges_mask</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span></span>
<span>    <span class="va">knn_idxl</span> <span class="op">&lt;-</span> <span class="va">nn_graph</span><span class="op">$</span><span class="va">idx</span><span class="op">[</span>, <span class="va">l</span><span class="op">]</span></span>
<span>    <span class="va">masked_knn_distl</span> <span class="op">&lt;-</span> <span class="va">nn_graph</span><span class="op">$</span><span class="va">dist</span><span class="op">[</span>, <span class="va">l</span><span class="op">]</span> <span class="op">*</span> <span class="va">too_few_edges_mask</span></span>
<span>    <span class="va">masked_knn</span> <span class="op">&lt;-</span> <span class="fu">vec_to_sp</span><span class="op">(</span><span class="va">knn_idxl</span>, <span class="va">masked_knn_distl</span><span class="op">)</span></span>
<span>    <span class="va">knn_adj</span> <span class="op">&lt;-</span> <span class="fu">sp_to_adj</span><span class="op">(</span><span class="va">masked_knn</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">mk_adj</span> <span class="op">&lt;-</span> <span class="va">bmnn_adj</span> <span class="op">+</span> <span class="va">knn_adj</span></span>
<span>    <span class="va">bmnn</span> <span class="op">&lt;-</span> <span class="va">bmnn</span> <span class="op">+</span> <span class="va">masked_knn</span></span>
<span>    <span class="va">bmnn</span><span class="op">@</span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">bmnn</span><span class="op">@</span><span class="va">x</span> <span class="op">/</span> <span class="va">mk_adj</span><span class="op">@</span><span class="va">x</span></span>
<span></span>
<span>    <span class="va">bmnn_adj</span> <span class="op">&lt;-</span> <span class="fu">sp_to_adj</span><span class="op">(</span><span class="va">bmnn</span><span class="op">)</span></span>
<span>    <span class="va">bmnn_edges</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">colSums</a></span><span class="op">(</span><span class="va">bmnn_adj</span><span class="op">)</span></span>
<span>    <span class="va">too_few_edges_mask</span> <span class="op">&lt;-</span> <span class="va">bmnn_edges</span> <span class="op">&lt;</span> <span class="op">(</span><span class="va">m</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">bmnn</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co">## Helper functions</span></span>
<span></span>
<span><span class="co"># truncate a dense neighbor graph to the first k neighbors</span></span>
<span><span class="va">nng</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">graph</span>, <span class="va">k</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>idx <span class="op">=</span> <span class="va">graph</span><span class="op">$</span><span class="va">idx</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">]</span>, dist <span class="op">=</span> <span class="va">graph</span><span class="op">$</span><span class="va">dist</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># convert a dense knn graph to a sparse matrix format</span></span>
<span><span class="co"># NB neighbors are stored by column</span></span>
<span><span class="va">nng_to_sp</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">graph</span>, <span class="va">nbrs</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">nbrs</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">graph</span> <span class="op">&lt;-</span> <span class="fu">nng</span><span class="op">(</span><span class="va">graph</span>, <span class="va">nbrs</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span></span>
<span>  <span class="va">idx</span> <span class="op">&lt;-</span> <span class="va">graph</span><span class="op">$</span><span class="va">idx</span></span>
<span>  <span class="va">dist</span> <span class="op">&lt;-</span> <span class="va">graph</span><span class="op">$</span><span class="va">dist</span></span>
<span>  <span class="va">n_nbrs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">idx</span><span class="op">)</span></span>
<span>  <span class="va">n_row</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">idx</span><span class="op">)</span></span>
<span>  <span class="va">n_ref</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">idx</span><span class="op">)</span></span>
<span>  <span class="va">i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html" class="external-link">as.vector</a></span><span class="op">(</span><span class="va">idx</span><span class="op">)</span></span>
<span>  <span class="va">j</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">n_row</span>, times <span class="op">=</span> <span class="va">n_nbrs</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html" class="external-link">as.vector</a></span><span class="op">(</span><span class="va">dist</span><span class="op">)</span></span>
<span>  <span class="va">keep_indices</span> <span class="op">&lt;-</span> <span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>  <span class="va">i</span> <span class="op">&lt;-</span> <span class="va">i</span><span class="op">[</span><span class="va">keep_indices</span><span class="op">]</span></span>
<span>  <span class="va">j</span> <span class="op">&lt;-</span> <span class="va">j</span><span class="op">[</span><span class="va">keep_indices</span><span class="op">]</span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="va">keep_indices</span><span class="op">]</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu">Matrix</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/sparseMatrix.html" class="external-link">sparseMatrix</a></span><span class="op">(</span>i <span class="op">=</span> <span class="va">i</span>, j <span class="op">=</span> <span class="va">j</span>, x <span class="op">=</span> <span class="va">x</span>, dims <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">n_row</span>, </span>
<span>      <span class="va">n_ref</span><span class="op">)</span>, repr <span class="op">=</span> <span class="va">repr</span><span class="op">)</span></span>
<span>  <span class="fu">Matrix</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/drop0.html" class="external-link">drop0</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># convert a sparse knn matrix to the mutual nearest neighbors graph</span></span>
<span><span class="va">sp_mutual</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">sp</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">sp_t</span> <span class="op">&lt;-</span> <span class="fu">Matrix</span><span class="fu">::</span><span class="fu">t</span><span class="op">(</span><span class="va">sp</span><span class="op">)</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">sp</span> <span class="op">*</span> <span class="va">sp_t</span><span class="op">)</span></span>
<span>  <span class="va">res</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># convert a dense kNN graph to a mutual nearest neighbors graph</span></span>
<span><span class="va">k_to_m</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">graph</span>, <span class="va">nbrs</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">sp</span> <span class="op">&lt;-</span> <span class="fu">nng_to_sp</span><span class="op">(</span><span class="va">graph</span>, <span class="va">nbrs</span><span class="op">)</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu">sp_mutual</span><span class="op">(</span><span class="va">sp</span><span class="op">)</span></span>
<span>  <span class="va">res</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># convert sparse matrix to an adjacency matrix (1 if there's an edge, 0 otherwise)</span></span>
<span><span class="va">sp_to_adj</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">sp</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">spi</span> <span class="op">&lt;-</span> <span class="va">sp</span></span>
<span>  <span class="va">spi</span><span class="op">@</span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">spi</span><span class="op">@</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">spi</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># convert the vector of values x to a sparse matrix with where the row is given</span></span>
<span><span class="co"># by the equivalent value in the vector i, and the column is the index of the</span></span>
<span><span class="co"># value in the vector x. The resulting matrix is a square matrix with the same </span></span>
<span><span class="co"># number of rows as the length of x.</span></span>
<span><span class="va">vec_to_sp</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">i</span>, <span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">n_row</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">i</span><span class="op">)</span></span>
<span>  <span class="va">j</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="va">n_row</span></span>
<span></span>
<span>  <span class="va">keep_indices</span> <span class="op">&lt;-</span> <span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>  <span class="va">i</span> <span class="op">&lt;-</span> <span class="va">i</span><span class="op">[</span><span class="va">keep_indices</span><span class="op">]</span></span>
<span>  <span class="va">j</span> <span class="op">&lt;-</span> <span class="va">j</span><span class="op">[</span><span class="va">keep_indices</span><span class="op">]</span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">x</span><span class="op">[</span><span class="va">keep_indices</span><span class="op">]</span></span>
<span>  <span class="va">res</span> <span class="op">&lt;-</span> <span class="fu">Matrix</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/sparseMatrix.html" class="external-link">sparseMatrix</a></span><span class="op">(</span></span>
<span>    i <span class="op">=</span> <span class="va">i</span>,</span>
<span>    j <span class="op">=</span> <span class="va">j</span>,</span>
<span>    x <span class="op">=</span> <span class="va">x</span>,</span>
<span>    dims <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">n_row</span>, <span class="va">n_row</span><span class="op">)</span>,</span>
<span>    repr <span class="op">=</span> <span class="st">"C"</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="fu">Matrix</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/drop0.html" class="external-link">drop0</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="disconnections-and-the-question-of-initialization">Disconnections and the Question of Initialization<a class="anchor" aria-label="anchor" href="#disconnections-and-the-question-of-initialization"></a>
</h2>
<p>Dalmia and Sia note that using a MNN graph leads to many disconnected
components, which can cause issues with the default spectral
initialization in UMAP. Their approach creates a connected graph to get
round this problem. An alternative I pursue in all the results here is
to always initialize from the first two components of PCA. Even in the
case of the kNN graph, you can still get disconnected components for a
given value of <code>n_neighbors</code>, and <code>uwot</code> will fall
back to PCA in this case anyway.</p>
</div>
<div class="section level2">
<h2 id="working-with-the-bmnn">Working with the BMNN<a class="anchor" aria-label="anchor" href="#working-with-the-bmnn"></a>
</h2>
<p>Putting this together, my recommended workflow is:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://jlmelville.github.io/rnndescent/" class="external-link">rnndescent</a></span><span class="op">)</span></span>
<span><span class="fu">librart</span><span class="op">(</span><span class="va">uwot</span><span class="op">)</span></span>
<span><span class="co"># get the approximate knn: use as many threads as you want</span></span>
<span><span class="va">data_knn_15</span> <span class="op">&lt;-</span> <span class="fu">rnndescent</span><span class="fu">::</span><span class="fu"><a href="https://jlmelville.github.io/rnndescent/reference/rnnd_knn.html" class="external-link">rnnd_knn</a></span><span class="op">(</span><span class="va">data</span>, k <span class="op">=</span> <span class="fl">15</span>, n_threads <span class="op">=</span> <span class="fl">6</span><span class="op">)</span></span>
<span><span class="co"># or if you have time on your hands</span></span>
<span><span class="co"># data_knn_15 &lt;- rnndescent::brute_force_knn(data, k = 15, n_threads = 6)</span></span>
<span></span>
<span><span class="va">pca_init</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap2.html">umap2</a></span><span class="op">(</span><span class="va">data</span>, nn_method <span class="op">=</span> <span class="va">data_knn_15</span>, init <span class="op">=</span> <span class="st">"pca"</span>, n_epochs <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Normal UMAP</span></span>
<span><span class="va">data_umap</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap2.html">umap2</a></span><span class="op">(</span><span class="va">data</span>, nn_method <span class="op">=</span> <span class="va">data_knn_15</span>, init <span class="op">=</span> <span class="va">pca_init</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create the (15, 5)-balanced MNN</span></span>
<span><span class="va">data_bmnn_15_5</span> <span class="op">&lt;-</span> <span class="fu">balance_mnn</span><span class="op">(</span><span class="va">data_knn_15</span>, k <span class="op">=</span> <span class="fl">15</span>, m <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># UMAP with BMNN</span></span>
<span><span class="va">data_bmnn_umap</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/umap2.html">umap2</a></span><span class="op">(</span><span class="va">data</span>, nn_method <span class="op">=</span> <span class="va">data_bmnn_15_5</span>, init <span class="op">=</span> <span class="va">pca_init</span><span class="op">)</span></span></code></pre></div>
<p>In the work presented by Dalmia and Sia, multiple choices of
<code>k</code> are tried (from 10-50) and some changes to
<code>min_dist</code>. I will stick with <code>k = 15</code> for all the
results shown here.</p>
</div>
<div class="section level2">
<h2 id="mnist-example">MNIST Example<a class="anchor" aria-label="anchor" href="#mnist-example"></a>
</h2>
<p>Does the BMNN graph produce results that differ from the kNN graph?
Let’s compare the UMAP embeddings of the <a href="https://yann.lecun.com/exdb/mnist/" class="external-link">MNIST digits</a> and <a href="https://github.com/zalandoresearch/fashion-mnist" class="external-link">Fashion
MNIST</a> datasets using the kNN graph and the BMNN graph. From left to
right we have the original UMAP embedding, the embedding using the (15,
2)-BMNN graph which should give similar results to the MNN+adjacent
neighbors approach used by Dalmia and Sia, and the an embedding using
the (15, 5)-BMNN graph which (I hope) should give a more “connected”
embedding. You can click on any of the images to see a (slightly) larger
version.</p>
<table class="table">
<colgroup>
<col width="35%">
<col width="21%">
<col width="21%">
<col width="21%">
</colgroup>
<thead><tr class="header">
<th align="center">Dataset</th>
<th>15-NN</th>
<th>(15,2)-BMNN</th>
<th>(15,5)-BMNN</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">MNIST</td>
<td><img src="img%2Fbmnn%2Fmnist-knn_15.png" alt="mnist-knn_15"></td>
<td><img src="img%2Fbmnn%2Fmnist-bmnn_15_2.png" alt="mnist-bmnn_15_2"></td>
<td><img src="img%2Fbmnn%2Fmnist-bmnn_15_5.png" alt="mnist-bmnn_15_5"></td>
</tr>
<tr class="even">
<td align="center">fashion</td>
<td><img src="img%2Fbmnn%2Ffashion-knn_15.png" alt="fashion-knn_15"></td>
<td><img src="img%2Fbmnn%2Ffashion-bmnn_15_2.png" alt="fashion-bmnn_15_2"></td>
<td><img src="img%2Fbmnn%2Ffashion-bmnn_15_5.png" alt="fashion-bmnn_15_5"></td>
</tr>
</tbody>
</table>
<p>Although it’s not that easy to see unless you click on the image, the
(15,2)-BMNN results do show a sprinkling of outlier points throughout
the embedding. This confirms the observations of Dalmia and Sia and so
this doesn’t seem like a promising approach. I won’t bother showing
results for (15,2)-BMNN graphs going forward. The (15,5)-BMNN on the
other hand seems quite well behaved. Now, if you were to say “I put it
to you that it doesn’t look very different from the normal UMAP results”
I would have to agree with you. But there is perhaps slightly more
separation of the clusters and some finer detail? Possibly that’s
entirely within the expected variation of a given UMAP run.</p>
<p>Fortunately there are some datasets where we do see more a
difference.</p>
</div>
<div class="section level2">
<h2 id="coil-20-and-coil-100">COIL-20 and COIL-100<a class="anchor" aria-label="anchor" href="#coil-20-and-coil-100"></a>
</h2>
<p>Embedding <a href="http://www.cs.columbia.edu/CAVE/software/softlib/coil-20.php" class="external-link">COIL-20</a>.
and <a href="http://www.cs.columbia.edu/CAVE/software/softlib/coil-100.php" class="external-link">COIL-100</a>
show a series of loops, but some of which typically get a bit tangled up
together or mangled. If ever there were some datasets that might benefit
from focusing on the mutual neighbors, it’s these two.</p>
<table class="table">
<colgroup>
<col width="45%">
<col width="27%">
<col width="27%">
</colgroup>
<thead><tr class="header">
<th align="center">Dataset</th>
<th>15-NN</th>
<th>(15,5)-BMNN</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">coil20</td>
<td><img src="img%2Fbmnn%2Fcoil20-knn_15.png" alt="coil20-knn_15"></td>
<td><img src="img%2Fbmnn%2Fcoil20-bmnn_15_5.png" alt="coil20-bmnn_15_5"></td>
</tr>
<tr class="even">
<td align="center">coil100</td>
<td><img src="img%2Fbmnn%2Fcoil100-knn_15.png" alt="coil100-knn_15"></td>
<td><img src="img%2Fbmnn%2Fcoil100-bmnn_15_5.png" alt="coil100-bmnn_15_5"></td>
</tr>
</tbody>
</table>
<p>I no longer feel like I am lying to myself when I say I can see a
difference between the two embeddings. The BMNN graph definitely seems
to have untangled the loops a bit more.</p>
</div>
<div class="section level2">
<h2 id="disappointing-results">Disappointing Results<a class="anchor" aria-label="anchor" href="#disappointing-results"></a>
</h2>
<p>There are some datasets which UMAP struggles to produce useful
results for. These include:</p>
<ul>
<li>the image dataset <a href="https://www.cs.toronto.edu/~kriz/cifar.html" class="external-link">CIFAR-10</a> where I
just wouldn’t expect looking at Euclidean distance in the raw pixel
space to produce anything of value (and it doesn’t).</li>
<li>the text dataset <a href="http://qwone.com/~jason/20Newsgroups/" class="external-link">20Newsgroups</a> that I
have attempted to <a href="https://jlmelville.github.io/uwot/articles/sparse-data-example.html">process
with UMAP</a> in the past: this version was cleaned, had TF-IDF applied
and then L2 normalized. Clusters do appear but they aren’t very
well-separated. This appears in the Dalmia and Sia paper with a
different processing (and also in the PaCMAP paper with a different
processing again) without looking terribly attractive.</li>
<li>The scRNA-seq data <a href="https://github.com/pavlin-policar/openTSNE/blob/master/examples/prepare_macosko_2015.ipynb" class="external-link">macosko2015</a>,
which in its raw form has around 3000 columns. It shows extreme hubness:
the MNN graph (with <code>k = 15</code>) results in 89% of the dataset
being entirely disconnected! A corresponding problem is that you have to
be quite careful with how large <code>m</code> is in the BMNN: as the
vast majority of edges in the kNN graph are pointing towards the hubs,
even a small number of additions of kNN edges back can lead to a hub in
the BMNN. The symmetrized kNN graph has a hub with 10,000 edges
associated with it (around 20% of the dataset). The BMNN graph with
<code>m = 5</code> reduces that, but the hub still has 4,000 edges.</li>
<li>
<code>macosko2015</code> visualizes more nicely with some PCA as the
hubness is greatly reduced (I am agnostic on if this representation more
faithfully represents the biological reality). so I also include the
same dataset after reducing to 100 dimensions with PCA.</li>
<li>The <a href="https://cs.nyu.edu/~yann/data/norb-v1.0-small/" class="external-link">Small
NORB</a> image dataset of objects, is not as challenging as the other
datasets listed here. In fact, it is slightly COIL-ish in that it
already shows some loops and other structure in UMAP. So could using the
MNN graph improve matters further as it has for COIL-20 and
COIL-100?</li>
</ul>
<table class="table">
<colgroup>
<col width="45%">
<col width="27%">
<col width="27%">
</colgroup>
<thead><tr class="header">
<th align="center">Dataset</th>
<th>15-NN</th>
<th>(15,5)-BMNN</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">norb</td>
<td><img src="img%2Fbmnn%2Fnorb-knn_15.png" alt="norb-knn_15"></td>
<td><img src="img%2Fbmnn%2Fnorb-bmnn_15_5.png" alt="norb-bmnn_15_5"></td>
</tr>
<tr class="even">
<td align="center">macosko2015</td>
<td><img src="img%2Fbmnn%2Fmacosko2015-knn_15.png" alt="macosko2015-knn_15"></td>
<td><img src="img%2Fbmnn%2Fmacosko2015-bmnn_15_5.png" alt="macosko2015-bmnn_15_5"></td>
</tr>
<tr class="odd">
<td align="center">macosko2015pca100</td>
<td><img src="img%2Fbmnn%2Fmacosko2015pca100-knn_15.png" alt="macosko2015pca100-knn_15"></td>
<td><img src="img%2Fbmnn%2Fmacosko2015pca100-bmnn_15_5.png" alt="macosko2015pca100-bmnn_15_5"></td>
</tr>
<tr class="even">
<td align="center">20NG</td>
<td><img src="img%2Fbmnn%2Fng20-knn_15.png" alt="ng20-knn_15"></td>
<td><img src="img%2Fbmnn%2Fng20-bmnn_15_5.png" alt="ng20-bmnn_15_5"></td>
</tr>
<tr class="odd">
<td align="center">cifar10</td>
<td><img src="img%2Fbmnn%2Fcifar10-knn_15.png" alt="cifar10-knn_15"></td>
<td><img src="img%2Fbmnn%2Fcifar10-bmnn_15_5.png" alt="cifar10-bmnn_15_5"></td>
</tr>
</tbody>
</table>
<p>Ok, so it turns out that the BMNN graph doesn’t really help in any of
these cases. <code>norb</code> is particularly disappointing in that it
noticeably makes things worse.</p>
<p>For <code>macosko2015</code>, pretty much nothing happens, except the
big blue round cluster has got some slight mottling where it seems like
some kind of fine(ish) structure is forming, which might translate to
clusters. I couldn’t tell you if it was biologically relevant though. I
tested whether the hubness that is present in the kNN and creeps back
into the BMNN is a determinant of this embedding by creating a BMNN
where edges were added back not in order of shortest distance, but in
smallest k-occurrence, i.e. items that appear the least often in the kNN
graph. This reduces the maximum edge count in the BMNN to around 200 (a
nearly 20-fold drop), but the embedding looks very similar to the
vanilla UMAP result:</p>
<table class="table">
<thead><tr class="header">
<th align="center">macosko2015 (15, 5)-koBMNN</th>
</tr></thead>
<tbody><tr class="odd">
<td align="center"><img src="img%2Fbmnn%2Fmacosko2015-kbmnn_15_5.png" alt="macosko2015-kbmnn_15_5"></td>
</tr></tbody>
</table>
<p>I include this image only because this is evidence against my
long-held belief that hubs in the kNN graph are a problem for UMAP, so
this is a good visualization for me to stare at the next time I start
going down this road. <code>macosko2015pca100</code> shows very little
change also.</p>
<p>For <code>20NG</code> and <code>cifar10</code> the only effect is to
make the main blob of data more compressed in the middle of the plot,
due to extra small clusters now being located at the edges. While not
attractive, this could be indicating some anomalous clustering in these
small subsets, which might be worth investigating further. For example,
these could be duplicates or close duplicates. I haven’t actually
<em>done</em> that investigation though so I can’t say if that’s the
case.</p>
<div class="section level3">
<h3 id="norb-revisited">norb revisited<a class="anchor" aria-label="anchor" href="#norb-revisited"></a>
</h3>
<p><em>December 29 2024</em>: Looking further at the <code>norb</code>
results, I couldn’t shake the feeling that the way the results were
broken up when going to the BMNN result indicated that the
<code>n_neighbors</code> was set too low. So let’s try with
<code>n_neighbors = 50</code>. I will set the BMNN to
<code>(50,5)</code>. Possilbly, a larger values of <code>k</code> means
we also need a larger value of <code>m</code> to get a good result but
let’s see if we can get away with just changing one parameter.</p>
<table class="table">
<colgroup>
<col width="45%">
<col width="27%">
<col width="27%">
</colgroup>
<thead><tr class="header">
<th align="center">Dataset</th>
<th>50-NN</th>
<th>(50,5)-BMNN</th>
</tr></thead>
<tbody><tr class="odd">
<td align="center">norb</td>
<td><img src="img%2Fbmnn%2Fnorb-knn_50.png" alt="norb-knn_50"></td>
<td><img src="img%2Fbmnn%2Fnorb-bmnn_50_5.png" alt="norb-bmnn_50_5"></td>
</tr></tbody>
</table>
<p>Ok, I am back to not hating BMNN for <code>norb</code>. Results are a
bit messy, but it’s definitely doing something: the BMNN separates out
the objects based on their class (the colors) to a much greater extent
than the kNN version, which has the results in more cleanly separated
clusters but with the classes more intertwined.</p>
</div>
</div>
<div class="section level2">
<h2 id="conclusions">Conclusions<a class="anchor" aria-label="anchor" href="#conclusions"></a>
</h2>
<p>Using the BMNN to approximate the MNN is a mixed bag. In some cases
it can help, but in others it either does very little, or can make
things worse – although there’s always a chance that this could be a
diagnostic of unusual structure in the data.</p>
<p>Also worth noting is that the BMNN graph is much sparser than the
symmetrized kNN graph that UMAP uses by default. In the examples here
the (15, 5)-BMNN graph has around 1/3-1/2 the number of edges of the kNN
graph. This can give a moderate speedup in the UMAP embedding step:
around 25-50%.</p>
<p>BMNN results are certainly not as visibly different as that seen in
the Dalmia and Sia paper. Why is this? It could be that I need to tweak
<code>k</code> and <code>m</code> specifically for each dataset although
that makes the BMNN approach very unappealing. It could also be that a
spectral initialization using the BMNN approach would give different
results, but in order to do that, we would need a strategy to form a
fully connected graph Laplacian. In general that would be a useful thing
to generate from any neighbor graph, but it seems like something that is
more suited to a graph or nearest neighbor package (like
<code>rnndescent</code>) than <code>uwot</code> itself.</p>
<p>Certainly the BMNN is no panacea to datasets that don’t show much
structure, but that was a pretty forlorn hope. My advice would be that
if your UMAP result does show some kind of structure, then it’s worth
trying the BMNN as it’s not difficult or time-consuming to generate. As
the <code>norb</code> example shows, if the BMNN destroys the
clustering, that could be a sign to try again with a larger values of
<code>n_neighbors</code>.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by James Melville.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
